{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from textblob import TextBlob\n",
    "from scipy import spatial\n",
    "import pickle\n",
    "import spacy\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dict embeddings from the files to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dict_emb1.pickle','rb') as f:\n",
    "    d1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dict_emb2.pickle','rb') as f:\n",
    "    d2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emb = dict(d1)\n",
    "dict_emb.update(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d1,d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load infersent model and dataframe\n",
    "The dataframe was created in dataset_parser.py from the **SQuAD 2.0 dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "infersent = torch.load('models/infersent_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add relevant columns to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(x):\n",
    "    idx = -1\n",
    "    for i in range(len(x[\"sentences\"])):\n",
    "        if x[\"text\"] in x[\"sentences\"][i]: idx = i\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(x):\n",
    "    question = x['question']\n",
    "    question_emb = dict_emb[question]\n",
    "    li = [spatial.distance.cosine(question_emb,dict_emb[sentence]) for sentence in x['sentences']]\n",
    "    return li + [1] * (10-len(li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentences'] = df['context'].apply(lambda x: [item.raw for item in TextBlob(x).sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentences'].map(len) <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distances'] = df.apply(get_cosine_sim, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the unique sentences and adding them to a dictionary\n",
    "The dictionary's values are the roots of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"sentences\"].reset_index(drop= True).tolist()\n",
    "s = set()\n",
    "for i in sentences:\n",
    "    for j in i:\n",
    "        s.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_roots = {}\n",
    "for sent in s:\n",
    "    sent_nlp = nlp(sent)\n",
    "    sent_roots[sent] = [chunk.root.head.lemma_ for chunk in sent_nlp.noun_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_roots(x):\n",
    "    question = x[\"question\"]\n",
    "    sentences = x['sentences']\n",
    "    question_root = [sent.root.lemma_ for sent in nlp(question).sents][0]\n",
    "    li = [int(question_root in sent_roots[sent]) for sent in sentences]\n",
    "    return li + [0]*(10 - len(li))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all the features\n",
    "Afterwards, save them to features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data):\n",
    "    columns = [f'column_root_{i}' for i in range(10)]\n",
    "    root_df = pd.DataFrame(data.apply(match_roots, axis= 1).tolist(), columns = columns)\n",
    "    \n",
    "    print('Finished creating root columns!')\n",
    "    \n",
    "    columns = [f'column_cos_{i}' for i in range(10)]\n",
    "    cos_df = pd.DataFrame(data.apply(get_cosine_sim, axis = 1).tolist(), columns = columns)\n",
    "    print('Finisehd creating distances columns!')\n",
    "    \n",
    "    train = pd.concat([root_df, cos_df], axis=1, sort=False)\n",
    "    train['target'] = data.apply(get_target,axis = 1)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating root columns!\n",
      "Finisehd creating distances columns!\n"
     ]
    }
   ],
   "source": [
    "train = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84346, 21)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/features.csv\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train/test data and trying different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['target'],axis = 1)\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, train_size=0.8, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy :  0.7377734305530855\n",
      "Random Forest Test Accuracy :  0.6816834617664493\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf=8, n_estimators=200)\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "print(\"Random Forest Train Accuracy : \", metrics.accuracy_score(train_y, rf.predict(train_x)))\n",
    "print(\"Random Forest Test Accuracy : \", metrics.accuracy_score(test_y, rf.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=1, score=0.680, total=   9.3s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=1, score=0.680, total=   9.9s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   19.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=1, score=0.680, total=   9.7s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=5 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   28.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=5, score=0.680, total=   9.4s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=5 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   38.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=5, score=0.680, total=   9.9s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=5, score=0.679, total=   9.5s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=10, score=0.680, total=   9.6s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=10, score=0.680, total=   9.9s\n",
      "[CV] learning_rate=0.07, max_depth=3, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.07, max_depth=3, min_child_weight=10, score=0.679, total=  10.4s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=1, score=0.687, total=  14.5s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=1, score=0.686, total=  14.4s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=1, score=0.688, total=  14.3s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=5, score=0.688, total=  13.7s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=5, score=0.686, total=  13.8s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=5, score=0.687, total=  13.5s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=10, score=0.687, total=  13.8s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=10, score=0.686, total=  14.1s\n",
      "[CV] learning_rate=0.07, max_depth=5, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.07, max_depth=5, min_child_weight=10, score=0.686, total=  14.1s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=1 ............\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=1, score=0.683, total=  25.0s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=1 ............\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=1, score=0.682, total=  25.9s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=1 ............\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=1, score=0.682, total=  24.8s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=5 ............\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=5, score=0.684, total=  25.0s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=5 ............\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=5, score=0.684, total=  23.8s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=5 ............\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=5, score=0.684, total=  24.6s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=10 ...........\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=10, score=0.684, total=  25.6s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=10 ...........\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=10, score=0.685, total=  23.8s\n",
      "[CV] learning_rate=0.07, max_depth=10, min_child_weight=10 ...........\n",
      "[CV]  learning_rate=0.07, max_depth=10, min_child_weight=10, score=0.686, total=  23.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=1, score=0.684, total=  10.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=1, score=0.685, total=  10.2s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=1, score=0.683, total=  11.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=5, score=0.684, total=  10.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=5, score=0.685, total=  10.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=5, score=0.683, total=   9.8s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=10, score=0.684, total=   9.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=10, score=0.685, total=   9.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.1, max_depth=3, min_child_weight=10, score=0.684, total=   9.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=0.687, total=  13.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=0.686, total=  13.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=1, score=0.688, total=  13.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=5, score=0.687, total=  13.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=5, score=0.686, total=  14.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=5, score=0.687, total=  13.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=10, score=0.687, total=  15.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=10, score=0.685, total=  16.2s\n",
      "[CV] learning_rate=0.1, max_depth=5, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.1, max_depth=5, min_child_weight=10, score=0.689, total=  15.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=0.682, total=  24.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=0.681, total=  24.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=1, score=0.684, total=  25.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=5, score=0.683, total=  23.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=5, score=0.682, total=  26.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=5, score=0.684, total=  26.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=10, score=0.684, total=  23.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=10, score=0.684, total=  23.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.1, max_depth=10, min_child_weight=10, score=0.686, total=  24.5s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=1, score=0.684, total=  10.8s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=1, score=0.686, total=  10.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=1, score=0.685, total=  11.6s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=5 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=5, score=0.684, total=  10.9s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=5, score=0.686, total=  10.3s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=5, score=0.685, total=  10.9s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=10, score=0.684, total=  11.1s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=10, score=0.686, total=  11.0s\n",
      "[CV] learning_rate=0.2, max_depth=3, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.2, max_depth=3, min_child_weight=10, score=0.685, total=  12.0s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=1, score=0.685, total=  14.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=1, score=0.684, total=  14.4s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=1 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=1, score=0.686, total=  14.5s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=5, score=0.685, total=  14.6s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=5, score=0.685, total=  14.4s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=5 ..............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=5, score=0.684, total=  14.2s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=10, score=0.684, total=  14.4s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=10, score=0.684, total=  14.2s\n",
      "[CV] learning_rate=0.2, max_depth=5, min_child_weight=10 .............\n",
      "[CV]  learning_rate=0.2, max_depth=5, min_child_weight=10, score=0.686, total=  13.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=1, score=0.678, total=  25.3s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=1, score=0.679, total=  24.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=1 .............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=1, score=0.679, total=  25.2s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=5, score=0.679, total=  23.6s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=5, score=0.679, total=  24.2s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=5 .............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=5, score=0.679, total=  24.5s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=10, score=0.681, total=  23.6s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=10, score=0.680, total=  23.9s\n",
      "[CV] learning_rate=0.2, max_depth=10, min_child_weight=10 ............\n",
      "[CV]  learning_rate=0.2, max_depth=10, min_child_weight=10, score=0.680, total=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 22.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estim...\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=False,\n",
       "                                     verbosity=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.07, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 10],\n",
       "                         'min_child_weight': [1, 5, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "param_dist = {\"max_depth\": [3,5,10],\n",
    "              \"min_child_weight\" : [1,5,10],\n",
    "              \"learning_rate\": [0.07, 0.1,0.2],\n",
    "               }\n",
    "# run randomized search\n",
    "grid_search = GridSearchCV(model, param_grid=param_dist, cv = 3, verbose=5)\n",
    "grid_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the best parameters for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Train Accuracy :  0.7139871954472702\n",
      "XGB Test Accuracy :  0.6953764078245406\n"
     ]
    }
   ],
   "source": [
    "xg = xgb.XGBClassifier(learning_rate=0.1,max_depth=5)\n",
    "xg.fit(train_x, train_y)\n",
    "\n",
    "print(\"XGB Train Accuracy : \", metrics.accuracy_score(train_y, xg.predict(train_x)))\n",
    "print(\"XGB Test Accuracy : \", metrics.accuracy_score(test_y, xg.predict(test_x)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
